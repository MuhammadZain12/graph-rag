llm:
  model_name: "gemma3:4b"
  temperature: 0.0
  provider: "ollama"
  extraction_provider: "gemini"

graph:
  chunk_size: 2000
  chunk_overlap: 500
